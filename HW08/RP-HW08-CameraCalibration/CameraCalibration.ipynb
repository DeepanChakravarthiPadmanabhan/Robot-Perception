{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dfe9894bf2e0935c9d50e3aa9e5cda18",
     "grade": false,
     "grade_id": "header_info",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\" >\n",
    "    <h1>Robot Perception</h1>\n",
    "    <h3>General Information:</h3>\n",
    "    <p>Please do not add or delete any cells. Answers belong into the corresponding cells (below the question). If a function is given (either as a signature or a full function), you should not change the name, arguments or return value of the function.<br><br> If you encounter empty cells underneath the answer that can not be edited, please ignore them, they are for testing purposes.<br><br>When editing an assignment there can be the case that there are variables in the kernel. To make sure your assignment works, please restart the kernel and run all cells before submitting (e.g. via <i>Kernel -> Restart & Run All</i>).</p>\n",
    "    <p>Code cells where you are supposed to give your answer often include the line  ```raise NotImplementedError```. This makes it easier to automatically grade answers. If you edit the cell please outcomment or delete this line. </p>\n",
    "    <br>The server resource is limited to 2 core cpu and 1GB RAM at max per user. If you use more than that, the kernel may die. Nevertheless, you can bring it up again by restaring the kernel (Kernel -> Restart and clear output).<br>\n",
    "    <h3>Submission:</h3>\n",
    "    <p>Upload all attachments required to run the notebook and provide a correct path to them.</p>\n",
    "    <p><strike>Please submit your notebook via the web interface (in the main view -> Assignments -> Submit)</strike>.</p> \n",
    "    <p>Starting from RP-HW07 onwards, submit the notebook and pdf version of it via LEA.</p>\n",
    "    <p>The assignments are due on <b>Monday at 0:00.</b> (i.e. Sunday 23:59 + 1 min)</p>\n",
    "    <h3>Group Work:</h3>\n",
    "    <p>You are allowed to work in groups of up to two people. Please enter the UID (your username here) of each member of the group into the next cell. We apply plagiarism checking, so do not submit solutions from other people except your team members. If an assignment has a copied solution, the task will be graded with 0 points for all people with the same solution.</p>\n",
    "    <p><b>YOU SHOULD ONLY SUBMIT EXACTLY ONE PER GROUP</b></p>\n",
    "    <h3>Questions about the Assignment:</h3>\n",
    "    <p>If you have questions about the assignment please post them in the LEA forum before the deadline. Don't wait until the last day to post questions.</p></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d8d622db9c87129fa84cea631c77806a",
     "grade": false,
     "grade_id": "header_warning",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<p><b>Put your answer in the PROVIDED CELLS only!</b></p>\n",
    "<b>Any new cell is not visible during the grading.</b>\n",
    "<p>We provide additional code and markdown cells for each question, so that you do not have to add the new ones.</p>\n",
    "<p>Do not copy the metadata from one cell to another as it is unique to that cell only.</p></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "55b0b9f8341b26a34bb9d1792b84f0bb",
     "grade": false,
     "grade_id": "members",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Group Work:\n",
    "Enter the UID (i.e. student2s) of each team member into the variables. \n",
    "If you work alone please leave the second variable empty, or extend this list if necessary.\n",
    "'''\n",
    "member1 = 'dpadma2s'\n",
    "member2 = 'jbandl2s'\n",
    "member3 = 'smuthi2s'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cd958afe1307bb29eff829fd57fe6c2f",
     "grade": false,
     "grade_id": "qa_description",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q&As: Pose three questions (and ans.) to last lecture, 3 Q&As per member [1 point]\n",
    "\n",
    "The format of the question and answer should be [Q1,A1,Q2,A2,Q3,A3,...,Qn,An], where Q1 is the question and A1 is the answer.<br>\n",
    "If you work in a group, the total of the Q&As is $3xn$, where $n$ is the total number of members.<br>\n",
    "\n",
    "Put your answer in the provided cell below!<br>\n",
    "If you work in a group, you can extend the provided Q&A template, but please use the same format:\n",
    "1. Q and A are separated by ONE $<$br$>$\n",
    "2. Q&A and other Q&As are separated by TWO $<$br$>$\n",
    "\n",
    "Or copy the provided format in the answer cell, and change the Q&A number.\n",
    "<br>\n",
    "Do not remove any markdown tag like $<$br$>$ in the answer cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "be944ca59eecc924dddf4b293192b057",
     "grade": true,
     "grade_id": "qa",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "<br>\n",
    "Q1 = What are normalized coordinates and normalized camera matrices?\n",
    "<br>\n",
    "A1 = The camera matrix $P$ for image 1 is given by, $P = K[R|t]$ and image point $x = PX$. $K$ is the intrinsic parameter matrix, $R$ is the rotation matrix and $t$ is the translation matrix. If $K$ is known, the inverse of $K$ is applied to an image point $x$ to obtain $\\hat x = K^{-1}x$. Then, $\\hat x= [R|t]X$, where $\\hat x$ is an image point in the normalized coordinates. The camera matrix, $K^{-1}P = [R|t]$ is called normalized camera matrix, removing the effect of the known calibration matrix.\n",
    "<br>\n",
    "<br>\n",
    "Q2 = What is Fundamental matrix, $F$ and Essential matrix, $E$?\n",
    "<br>\n",
    "A2 = \n",
    "\n",
    "**Fundamental matrix:**\n",
    "\n",
    "The fundamental matrix, $F$ is a 3x3 rank 2 matrix mapping a point in image 1 to the corresponding line $l'$ in image 2. ie., $l'=Fx$. Since the point $x'$ corresponding to $x$ necessarily lies on $l'$, we know that $x'^Tl'=0$ and therefore, $x'^T F x =0$. This allows us to compute F from a set of point correspondences {$x_i \\leftrightarrow x_i'$}\n",
    "\n",
    "**Essential matrix:**\n",
    "\n",
    "The essential matrix, $E$ is a specialization to the case of normalized image coordinates. The camera matrix $P$ for image 1 is given by, $P = K[R|t]$ and image point $x = PX$. $K$ is the intrinsic parameter matrix, $R$ is the rotation matrix and $t$ is the translation matrix. If $K$ is known, the inverse of $K$ is applied to an image point $x$ to obtain $\\hat x = K^{-1}x$. Then, $\\hat x= [R|t]X$, where $\\hat x$ is an image point in the normalized coordinates. The camera matrix, $K^{-1}P = [R|t]$ is called normalized camera matrix, removing the effect of the known calibration matrix. On considering, a pair of normalized camera matrices, $P = [I|0]$ and $P' = [R|t]$. The fundamental matrix corresponding to the pair of normalized cameras is the essential matrix.\n",
    "\n",
    "$E = [t]_xR = R[R^t]_x$\n",
    "\n",
    "Therefore, $E$ is given by $\\hat x'^T E \\hat x=0$ where, $\\hat x'$ and $\\hat x$ are normalized image cooridinates for the corresponding points $x \\leftrightarrow x'$ on image 1 and image 2.\n",
    "<br>\n",
    "<br>\n",
    "Q3 = Give the degrees of freedom (DOF) of camera matrix, fundamental matrix and homography.\n",
    "<br>\n",
    "A3 = \n",
    "\n",
    "**Camera matrix, $P$: 11 DOF** \n",
    "\n",
    "* 3 x 4 matrix, total 12 elements in the matrix.\n",
    "* One of the element can be used for scaling and normalizing, therefore a total of 11 DOF.\n",
    "\n",
    "**Fundamental matrix, $F$: 7 DOF**\n",
    "\n",
    "* 3 x 3, rank 2 matrix, total 9 elements in the matrix.\n",
    "* One of the element can be used for scaling and normalizing, therefore, now 8 elements.\n",
    "* Since $F$ is a rank 2 matrix mapping a point in image 1 to line in image 2, it looses another parameter resulting in a total of 7 DOF.\n",
    "\n",
    "**Homography, $H$: 15 DOF**\n",
    "\n",
    "* 4 x 4 matrix, total 16 elements in the matrix.\n",
    "* One of the element can be used for scaling and normalizing, therefore a total of 15 DOF.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "Q4 = Your first question here!\n",
    "<br>\n",
    "A4 = Your Q1 answer here!\n",
    "<br>\n",
    "<br>\n",
    "Q5 = Your second question here!\n",
    "<br>\n",
    "A5 = Your Q2 answer here!\n",
    "<br>\n",
    "<br>\n",
    "Q6 = Your third question here!\n",
    "<br>\n",
    "A6 = Your Q3 answer here!\n",
    "<br>\n",
    "<br>\n",
    "Q7 = Your first question here!\n",
    "<br>\n",
    "A7 = Your Q1 answer here!\n",
    "<br>\n",
    "<br>\n",
    "Q8 = Your second question here!\n",
    "<br>\n",
    "A8 = Your Q2 answer here!\n",
    "<br>\n",
    "<br>\n",
    "Q9 = Your third question here!\n",
    "<br>\n",
    "A9 = Your Q3 answer here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dd37e964d3c5281852567329d2725f85",
     "grade": false,
     "grade_id": "time",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Provide the time required to solve the assignment per task as well as the sum (in minutes).\n",
    "Extend this list if needed.\n",
    "'''\n",
    "\n",
    "Task1 = 0\n",
    "Task2 = 0\n",
    "Task3 = 0\n",
    "Task4 = 0\n",
    "Sum = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "45e612d2e1124f1fb3f91c62c8165d80",
     "grade": false,
     "grade_id": "task1_description",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task1: Read this [MATLAB explanation](https://de.mathworks.com/help/vision/examples/measuring-planar-objects-with-a-calibrated-camera.html). Rehearse this experiment using your own smart phone camera (or some BETTER camera if available) , in openCV (if possible) and use a different object (like a book, match box etc). Then: \n",
    "### - Compare your result to the measurements done on the real object. How large is the difference? \n",
    "### - Taking your observed error, is this lay inside the error bounds produced by the calibration algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1c83894d1222f38c916df23aba789943",
     "grade": true,
     "grade_id": "task1",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "webcam_2/corners/my_photo-20.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "webcam_2/corners/my_photo-4.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "webcam_2/corners/my_photo-10.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "webcam_2/corners/my_photo-25.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "webcam_2/corners/my_photo-30.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera matrix (Focal length in mm):\n",
      " [[ 20.60025669   0.         964.61858884]\n",
      " [  0.          36.31960977 522.84961464]\n",
      " [  0.           0.           1.        ]]\n",
      "Distortion coefficients:\n",
      " [[-0.01846476  0.12160998  0.01312348  0.00331914 -0.30123076]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from copy import deepcopy\n",
    "import rawpy\n",
    "\n",
    "def get_points(images_path,pattern_shape):\n",
    "    # termination criteria\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((pattern_shape[0]*pattern_shape[1],3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:pattern_shape[0],0:pattern_shape[1]].T.reshape(-1,2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d point in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "    images = glob.glob(images_path+'*.jpg')\n",
    "    count = 0\n",
    "    for fname in images:\n",
    "#         with rawpy.imread(fname) as raw:\n",
    "#             img = raw.postprocess()\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        # Find the chess board corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (pattern_shape[0],pattern_shape[1]),None)\n",
    "        # If found, add object points, image points (after refining them)\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "\n",
    "            corners2 = cv2.cornerSubPix(gray,corners,(11,11),(-1,-1),criteria)\n",
    "            imgpoints.append(corners2)\n",
    "            # Display only five images\n",
    "            if count<5:\n",
    "                plt.figure(figsize=(15,10))\n",
    "                # Draw and display the corners\n",
    "                img = cv2.drawChessboardCorners(img, (pattern_shape[0],pattern_shape[1]), corners2,ret)\n",
    "                plt.imshow(img)\n",
    "                plt.title('Images with corners marked, example {}'.format(count+1))\n",
    "                plt.xlabel('Width, x axis')\n",
    "                plt.ylabel('Height, y axis')\n",
    "#                 filename = os.path.split(fname)[-1]\n",
    "#                 filename = filename.split(\".\")\n",
    "                save_path = \"webcam_2/corners/\"+os.path.split(fname)[-1].split(\".\")[0]+\".png\"\n",
    "                print(save_path)\n",
    "                plt.imsave(save_path,img)\n",
    "                plt.show()\n",
    "            count+=1\n",
    "            \n",
    "    return objpoints, imgpoints, gray.shape[::-1]\n",
    "\n",
    "def camera_calibration(objpoints,imgpoints,image_shape):\n",
    "    return cv2.calibrateCamera(objpoints, imgpoints, image_shape,None,None)\n",
    "\n",
    "def get_newmatrix(mtx,dist,image_shape):\n",
    "    w = image_shape[0]\n",
    "    h = image_shape[1]\n",
    "    return cv2.getOptimalNewCameraMatrix(mtx,dist,(w,h),1,(w,h))\n",
    "\n",
    "def undistort_image(image,mtx,dist,newcameramtx,roi):\n",
    "    # undistort\n",
    "    dst = cv2.undistort(image, mtx, dist, None, newcameramtx)\n",
    "\n",
    "    # crop the image\n",
    "    x,y,w,h = roi\n",
    "    dst = dst[y:y+h, x:x+w]\n",
    "    return dst\n",
    "\n",
    "\n",
    "images_path = \"./webcam_2/\"\n",
    "pattern_shape = [7,9]\n",
    "objpoints,imgpoints,image_shape = get_points(images_path,pattern_shape)\n",
    "ret, mtx, dist, rvecs, tvecs = camera_calibration(objpoints,imgpoints,image_shape)\n",
    "\n",
    "# Here the focal lengths are in pixels.\n",
    "newcameramtx, roi = get_newmatrix(mtx,dist,image_shape)\n",
    "\n",
    "# Conversion from pixels to mm scale for focal length\n",
    "one_plus_sensorwidth = 25\n",
    "image_width = image_shape[0]\n",
    "image_height = image_shape[1]\n",
    "new_camera_matix = deepcopy(mtx)\n",
    "# F(mm) = F(pixel) * sensorwidth/image_width \n",
    "new_camera_matix[0][0] = new_camera_matix[0][0] * one_plus_sensorwidth /image_width\n",
    "new_camera_matix[1][1] = new_camera_matix[1][1] * one_plus_sensorwidth /image_height\n",
    "\n",
    "\n",
    "print(\"Camera matrix (Focal length in mm):\\n\",new_camera_matix)\n",
    "# print(\"Rotation vector:\\n\",rvecs)\n",
    "# print(\"Translation vector:\\n\",tvecs)\n",
    "print(\"Distortion coefficients:\\n\",dist)\n",
    "# print(\"New camera matrix:\\n\",newcameramtx)\n",
    "\n",
    "with open(\"camera_parameter_file.txt\",'w',encoding = 'utf-8') as f:\n",
    "    f.write(\"Camera matrix:\\n\")\n",
    "    f.write(\"(Focal length, fx, fy are in mm)\\n\\n\")\n",
    "    for item in new_camera_matix:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "    f.write(\"\\nDistortion matrix\\n\\n\")\n",
    "    for item in dist:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ecdbab0871b446fd09e0dc7b30ae23b6",
     "grade": false,
     "grade_id": "task1_code1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "mean_error = 0\n",
    "for i in range(0,len(objpoints)):\n",
    "    imgpoints2, _ = cv2.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist)\n",
    "    error = cv2.norm(imgpoints[i],imgpoints2, cv2.NORM_L2)/len(imgpoints2)\n",
    "    mean_error += error\n",
    "\n",
    "print (\"projection error: \", mean_error/len(objpoints))\n",
    "image = cv2.imread(\"test_images/my_photo-1.jpg\")\n",
    "undistorted_image = undistort_image(image,mtx,dist,mtx,roi)\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.title(\"distored image\")\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.title(\"un distored image\")\n",
    "plt.imshow(undistorted_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d311521e49dbe3d724e3185d4f403e9f",
     "grade": false,
     "grade_id": "task1_code2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import imutils\n",
    "folder_path = \"./planarmeasure/webcam/\"\n",
    "img_paths = glob.glob(folder_path+\"*jpg\")\n",
    "\n",
    "rvec = np.mean(rvecs,axis=0)\n",
    "# rvec = rvecs[0]\n",
    "tvec = np.reshape(np.mean(tvecs,axis=0),(3,1))\n",
    "# tvec = tvecs[0]\n",
    "r_mat,_ = cv2.Rodrigues(rvec)\n",
    "H = np.hstack((r_mat,tvec))\n",
    "# print(H)\n",
    "\n",
    "# (_, rvec, tvec) = cv2.solvePnP(np.float32(objpoints), np.float64(imgpoints),mtx, dist)\n",
    "\n",
    "\n",
    "def embed_from_R2_to_P2(point):\n",
    "    '''\n",
    "    Function to embed a point from R2 into P2\n",
    "    parameters:\n",
    "        point: ndarray: A point in R2\n",
    "    return:\n",
    "        point: ndarray: A point in P2\n",
    "    '''\n",
    "    point_in_P2 = np.append(point,1)\n",
    "    return np.reshape(point_in_P2,(len(point_in_P2),1))\n",
    "def normalize_point(point):\n",
    "    '''\n",
    "    Function to normalize a given point in P2\n",
    "    parameters:\n",
    "        point: ndarray: A point in P2\n",
    "    return:\n",
    "        normalized point: ndarray: A normalized point in P2\n",
    "    '''\n",
    "    return point/point[-1]\n",
    "\n",
    "\n",
    "def project_to_world_coordinated(point,H,mtx):\n",
    "#     print(point)\n",
    "    cx = mtx[0][2]\n",
    "    cy = mtx[1][2]\n",
    "    fx = mtx[0][0]\n",
    "    fy = mtx[1][1]\n",
    "    u = point[0] - cx\n",
    "    v = point[1] - cy\n",
    "    point_wrt_center = np.array([u,v,fx])\n",
    "    point_camera_coordinates = np.reshape(np.dot(np.linalg.pinv(mtx),point_wrt_center),(3,1))\n",
    "    world_point = np.dot(np.linalg.pinv(r_mat),point_camera_coordinates) - tvec\n",
    "    return world_point\n",
    "for f in img_paths:\n",
    "    img = cv2.imread(f)\n",
    "    img = undistort_image(img,mtx,dist,newcameramtx,roi)\n",
    "    pixx,pixy,_= img.shape\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.threshold(gray, 0, 255,cv2.THRESH_BINARY_INV| cv2.THRESH_OTSU)[1]\n",
    "    kernel = np.ones((4, 4), np.uint8)\n",
    "    closing = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=7)\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    closing = cv2.morphologyEx(closing, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "    cont_img = closing.copy()\n",
    "    cnts = cv2.findContours(cont_img, cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "#     loop over the contours\n",
    "    for (i, c) in enumerate(cnts):\n",
    "        approx = cv2.approxPolyDP(c,0.01*cv2.arcLength(c,True),True)\n",
    "        area = cv2.contourArea(c)\n",
    "        if len(approx) in range(10,15) and (pixx*pixy/200) > area > (pixx*pixy/1300):\n",
    "            # draw the contour\n",
    "            x, y, w, h = cv2.boundingRect(c)\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2) \n",
    "            point1 = project_to_world_coordinated([x,y],H,mtx)\n",
    "            point2 = project_to_world_coordinated([x+w,y],H,mtx)\n",
    "#             print(point1.shape,point2)\n",
    "            print(np.linalg.norm(point1-point2))\n",
    "            cv2.drawContours(img, [c], -1, (0, 255, 0), 5)\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.imshow(cv2.cvtColor(closing,cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2dade55778df86d2802edec088abf0a7",
     "grade": true,
     "grade_id": "task1_md1",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6cb232210c81c5fa7e49d7722e96b1b3",
     "grade": false,
     "grade_id": "task2_description",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "##  Task2: Compare the MATLAB calibration process and the respective openCV calibration using Python, spell out in detail : \n",
    "### - Similarities / differences. \n",
    "### - Will both tools produce IDENTICAL results for IDENTICAL cameras? \n",
    "### - What makes the difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "25ba32577e0b9be0eb028a80a47ca34a",
     "grade": true,
     "grade_id": "task2",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6dd119b1487199beca927c3059b784cc",
     "grade": false,
     "grade_id": "task2_code1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8475225a3deb90342c903788d146fd9e",
     "grade": true,
     "grade_id": "task2_md1",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "14257b0b20a6530871e72af8e8cdce30",
     "grade": false,
     "grade_id": "task3_description",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task3: Read the slide set read the subsection on \"Computation of F\" (OR check the book Chapter 11). Implement a Normalized 8 point algorithm.\n",
    "\n",
    "### Use the following signature: \n",
    "\n",
    "#### `fNorm8Point = estimateFundamentalMatrix(inlierPts1, inlierPts2)` \n",
    "\n",
    "where the inliers denote the pixel coordinates of corresponding points in left / right image. \n",
    "\n",
    "Image material can be found under images, and also some point arrays (`FMatrixCorrPointsStereo.txt`) for corresponding points in left and right image of image number 7 (`images/7.picture-24.jpg`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7ebf8b27ea77494dc7d82f12cf222319",
     "grade": true,
     "grade_id": "task3",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b5dcc5d135e48abb1debf174cc14cef",
     "grade": false,
     "grade_id": "task3_code1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f0a35c91c5d9d213812b3cf2a94756a9",
     "grade": true,
     "grade_id": "task3_md1",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "298b39f60805ad5697aeead07840fce2",
     "grade": false,
     "grade_id": "task4_description",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task4: Draw the respective epipoles on top of the images based the matrix F and corresponding points you found in task4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8bf072c73dff5e7076ed38ea9af8a8fb",
     "grade": true,
     "grade_id": "task4",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a20b318bc9416fa054cde7a4e89a01a6",
     "grade": false,
     "grade_id": "task4_code1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1678b3718242d9ae60853203a8c844d1",
     "grade": true,
     "grade_id": "task4_md1",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python rnd-tf",
   "language": "python",
   "name": "rnd-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
