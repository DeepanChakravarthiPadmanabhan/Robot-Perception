{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "03aab208de3137452001eb2491cc2c1f",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\" >\n",
    "    <h1>Robot Perception</h1>\n",
    "    <h3>General Information:</h3>\n",
    "    <p>Please do not add or delete any cells. Answers belong into the corresponding cells (below the question). If a function is given (either as a signature or a full function), you should not change the name, arguments or return value of the function.<br><br> If you encounter empty cells underneath the answer that can not be edited, please ignore them, they are for testing purposes.<br><br>When editing an assignment there can be the case that there are variables in the kernel. To make sure your assignment works, please restart the kernel and run all cells before submitting (e.g. via <i>Kernel -> Restart & Run All</i>).</p>\n",
    "    <p>Code cells where you are supposed to give your answer often include the line  ```raise NotImplementedError```. This makes it easier to automatically grade answers. If you edit the cell please outcomment or delete this line.</p>\n",
    "    <br>The server resource is limited to 2 core cpu and 1GB RAM at max per user. If you use more than that, the kernel may die. Nevertheless, you can bring it up again by restaring the kernel (Kernel -> Restart and clear output).<br>\n",
    "    <h3>Submission:</h3>\n",
    "    <p>Please submit your notebook via the web interface (in the main view -> Assignments -> Submit). The assignments are due on <b>Monday at 0:00.</b> (i.e. Sunday 23:59 + 1 min)</p>\n",
    "    <h3>Group Work:</h3>\n",
    "    <p>You are allowed to work in groups of up to two people. Please enter the UID (your username here) of each member of the group into the next cell. We apply plagiarism checking, so do not submit solutions from other people except your team members. If an assignment has a copied solution, the task will be graded with 0 points for all people with the same solution.</p>\n",
    "    <p><b>YOU SHOULD ONLY SUBMIT EXACTLY ONE PER GROUP</b></p>\n",
    "    <h3>Questions about the Assignment:</h3>\n",
    "    <p>If you have questions about the assignment please post them in the LEA forum before the deadline. Don't wait until the last day to post questions.</p></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "63d6fcd0732d39306f809c2277db793c",
     "grade": false,
     "grade_id": "header2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<p><b>Put your answer in the PROVIDED CELLS only!</b></p>\n",
    "<b>Any new cell is not visible during the grading.</b>\n",
    "<p>There is one code and markdown cell available for each question, so that you can use one or both of them according to the type of the question.</p>\n",
    "<p>Do not copy the metadata from one cell to another, it is unique to that cell only.</p></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Group Work:\n",
    "Enter the UID (i.e. student2s) of each team member into the variables. \n",
    "If you work alone please leave the second variable empty.\n",
    "'''\n",
    "member1 = 'dpadma2s'\n",
    "member2 = 'jbandl2s'\n",
    "member3 = 'smuthi2s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "042d28e7df55ef780f774a30e7928893",
     "grade": false,
     "grade_id": "time",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Put here the average solution time for the full exercise set in estimated MINUTES\".\n",
    "AverageSolutionTimeinMinutes should be > or < 4711\n",
    "i.e.\n",
    "AverageSolutionTimeinMinutes = 180\n",
    "'''\n",
    "\n",
    "AverageSolutionTimeinMinutes = 840"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "77c82ae9b4d29e40c20427768b1a6045",
     "grade": true,
     "grade_id": "time_test",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This is a test cell, please ignore it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ba46697c49deb7f75491a482b98a7699",
     "grade": false,
     "grade_id": "task1_description",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    " # Task 1 : Pose three questions (and ans.) to last lecture [1 point]\n",
    " The format of the question and answer should be [Q1,A1,Q2,A2,Q3,A3], where Q1 is the question and A1 is the answer.\n",
    "Both Q and A should contain equal to or more than three words. Do not remove any markdown tag like $<$br$>$ in the answer cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a0875f7137b0b73989e061f1c902a109",
     "grade": true,
     "grade_id": "task1",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Q1 = What are some situations that require estimation of homography?\n",
    "<br>\n",
    "A1 = Few of the situations are:\n",
    "* Camera calibration\n",
    "* 3D reconstruction\n",
    "* Visual metrology\n",
    "* Stereo vision\n",
    "* Scene understanding\n",
    "* Automatic Mosaicing\n",
    "<br>\n",
    "<br>\n",
    "Q2 = Why line based approaches are better than point based approaches in homography estimation?\n",
    "<br>\n",
    "A2 = It is a conventional belief that line-based approaches perform better than point-based ones for homography estimation, as the linefitting is generally more noise resistant than point detection.\n",
    "<br>\n",
    "<br>\n",
    "Q3 = When can two images be related by homography?\n",
    "<br>\n",
    "A3 = Two images can have relation through homography if and only if:\n",
    "* Both images are viewing the same plane from a different prespective.\n",
    "* Both images are taken from the same camera but from different angle.\n",
    "* Camera should be rotated along its origin of projection and there should not be any translation.\n",
    "* Homography relation is independent of scene structure. So, it do not depend on what cameras are capturing and still relationship can be established irrespective of what is seen in images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c14664256a88a2461081251e739c3868",
     "grade": true,
     "grade_id": "task1_test",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This is a test cell, please ignore it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ed2b4fd55991bc4746f59130088f3d07",
     "grade": false,
     "grade_id": "task2_description",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Task 2: Read parts of chapter 4 (Estimation â€“ 2D Projective Transformations) of MVG namely 4.1, 4.4., 4.6., 4.7., 4.8. [1 point]<br>Produce some sort of a summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a43bb17412811edf7c5bdc62e38a6a2f",
     "grade": true,
     "grade_id": "task2",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "<img src=\"boat/2DProjectiveTransformation-Estimation.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "88b9db3faa1b994e3f690f9b8b09766f",
     "grade": false,
     "grade_id": "task3_description",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Task 3: Implement Algor 4.2 (normalized DLT) in python by HAND, don't use the in-build image tool boxes. [3 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7ebf8b27ea77494dc7d82f12cf222319",
     "grade": true,
     "grade_id": "task3",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desired Homography, H:\n",
      " [[  0.87545097   0.23238266   3.4699619 ]\n",
      " [ -0.21413475   0.87925678 129.60815544]\n",
      " [  0.00001108   0.0000304    1.        ]]\n"
     ]
    }
   ],
   "source": [
    "import typing\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import image\n",
    "import cv2\n",
    "\n",
    "class Perform_DLT():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        np.set_printoptions(suppress=True)\n",
    "        \n",
    "    def get_correspondence_point(self, points_file: str, img_x: np.ndarray, img_xprime: np.ndarray) -> np.ndarray:\n",
    "        '''\n",
    "        Parser to read the correspondence points in img1 and img2\n",
    "        '''\n",
    "        \n",
    "        self.points_file = points_file\n",
    "        self.img_x = img_x\n",
    "        self.img_xprime = img_xprime\n",
    "\n",
    "        f = open(self.points_file)\n",
    "\n",
    "        image_points = dict()\n",
    "        for n,line in enumerate(f.readlines()):\n",
    "\n",
    "            line = line.replace('[','').replace(']','').strip()\n",
    "            pointlist = line.split('=')[1].split(';')\n",
    "            x = list()\n",
    "            y = list()\n",
    "\n",
    "            for point in pointlist:\n",
    "                x.append(int(point.split(',')[0]))\n",
    "                y.append(int(point.split(',')[1]))\n",
    "            image_points[n] = np.vstack((x,y))\n",
    "\n",
    "        return image_points[0], image_points[1]\n",
    "\n",
    "    def normalize(self, x: np.ndarray) -> np.ndarray:\n",
    "        \n",
    "        '''\n",
    "        Normalizes a given matrix, x by performing similarity transformation.\n",
    "        Now the centroid of the new points has (0,0)^T and the average distance \n",
    "        from the origin is square.root(2)\n",
    "        '''\n",
    "\n",
    "        x_bar = np.asarray(x)\n",
    "        m = np.mean(x,1)\n",
    "\n",
    "        deno = list()\n",
    "\n",
    "        for i in x.transpose():\n",
    "            deno.append(list(i-m))\n",
    "        deno = np.square(np.array(deno))\n",
    "        total = 0\n",
    "        for i in deno:\n",
    "            total = sum(i)**(1/2.) + total\n",
    "\n",
    "        s = 2**(1/2)/(total/len(deno))\n",
    "\n",
    "        T = np.array([[s, 0, -s*m[0]], [0, s, -s*m[1]], [0, 0, 1]])\n",
    "\n",
    "        x = np.vstack((x, np.ones((1,x.shape[1]))))\n",
    "\n",
    "        x_bar = np.dot(T, x)\n",
    "        \n",
    "        return x_bar, T\n",
    "\n",
    "    def DLT(self, x: np.ndarray, x_bar: np.ndarray) -> np.ndarray:\n",
    "        '''\n",
    "        Performs DLT on the x and x' provided\n",
    "        '''\n",
    "\n",
    "        # Initializations for A matrix\n",
    "        a_12 = list()\n",
    "        a_13 = list()\n",
    "        a_21 = list()\n",
    "        a_23 = list()\n",
    "        result = list()\n",
    "        \n",
    "        # Forming A matrix as provided in Reference 1 and Hartley and zisserman multiple view geometry\n",
    "\n",
    "        for i,j in zip(x.transpose(), x_bar.transpose()):\n",
    "\n",
    "            a_12= np.array([list(-np.dot(j[2],i.transpose()))])\n",
    "            a_13= np.array([list(np.dot(j[1],i.transpose()))])\n",
    "            a_21= np.array([list(np.dot(j[2],i.transpose()))])\n",
    "            a_23= np.array([list(-np.dot(j[0],i.transpose()))])\n",
    "\n",
    "            r1 = np.hstack((np.hstack((np.zeros((1,3)),a_12)),a_13))\n",
    "            r2 = np.hstack((np.hstack((a_21,np.zeros((1,3)))),a_23))\n",
    "\n",
    "            a = np.vstack((r1,r2))   \n",
    "\n",
    "            for k in a:\n",
    "                result.append(list(k))\n",
    "\n",
    "        A = np.array(result)\n",
    "        \n",
    "        \n",
    "        # Ah = 0 ;Minimizing ||Ah|| such that ||h||=1\n",
    "        # Solution by SVD\n",
    "        \n",
    "        U,s,Vt = np.linalg.svd(A)\n",
    "        V=Vt.T\n",
    "        h=V[:,-1] # Last column of V corresponding eigen vector to the smallest eigen value\n",
    "        \n",
    "        h = np.reshape(h,(3,3))\n",
    "\n",
    "        return h\n",
    "    \n",
    "    def desired_H(self, T_bar, T_prime_bar, H_normalized):\n",
    "        \n",
    "        '''\n",
    "        Used for finding H in unnormalized original co-ordinates from normalized H' by performing,\n",
    "        H = inverse(T') H' T\n",
    "        '''\n",
    "        non_scaled_H = np.dot(np.linalg.inv(T_prime_bar),(np.dot(H_normalized, T_bar)))\n",
    "        # Scaling H such that H(3,3) is 1.\n",
    "        desired_H = non_scaled_H/non_scaled_H[2][2]\n",
    "        \n",
    "        return desired_H\n",
    "    \n",
    "    \n",
    "img_path1 = 'boat/img1+points.png'\n",
    "img_path2 = 'boat/img2+points.png'\n",
    "img1 = image.imread(img_path1)\n",
    "img2 = image.imread(img_path2)\n",
    "points_file = 'boat/homography.txt'\n",
    "\n",
    "homography = Perform_DLT()\n",
    "\n",
    "# Get initial corresponding points\n",
    "x, x_prime = homography.get_correspondence_point(points_file, img1, img2)   \n",
    "\n",
    "# Normalize x to overcome the numerical calculation issues in DLT\n",
    "x_bar, T_bar = homography.normalize(x)\n",
    "\n",
    "# Normalize x' to overcome the numerical calculation issues in DLT\n",
    "x_prime_bar, T_prime_bar = homography.normalize(x_prime)\n",
    "\n",
    "# Find H normalized\n",
    "H_normalized = homography.DLT(x_bar, x_prime_bar)\n",
    "\n",
    "# Find H mapping to original image scales.\n",
    "H = homography.desired_H(T_bar, T_prime_bar, H_normalized)\n",
    "\n",
    "print('Desired Homography, H:\\n', H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "799eeffa384605e8fde2dcbecb0b6faa",
     "grade": true,
     "grade_id": "task3_md",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Steps:\n",
    "1. Read correspondence points in 2 images.\n",
    "2. Normalize x and x' to overcome the numerical calculation issues in DLT.\n",
    "3. Find H normalized (H') by performing DLT.\n",
    "Ah = 0 ;Minimizing ||Ah|| such that ||h||=1\n",
    "h - Last column of V corresponding eigen vector to the smallest eigen value\n",
    "4. Find H mapping to original image scales.\n",
    "Used for finding H in unnormalized original co-ordinates from normalized H' by performing,\n",
    "H = inverse(T') H' T\n",
    "\n",
    "Desired Homography, H:\n",
    " [[  0.87545097   0.23238266   3.4699619 ]\n",
    " [ -0.21413475   0.87925678 129.60815544]\n",
    " [  0.00001108   0.0000304    1.        ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "325aa54cfb340dc2269d902d248cc8c8",
     "grade": false,
     "grade_id": "task4_description",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Task 4: Validate your results using the test images and by comparison TO the in build image library methods! Use the images found in the \"./boat/\" sub-dir (or any other you pick: needed: 2 images and two lists of corresponding point pair coordinates,pls provide MORE test cases)[1 point]<br>NB I am not 100% sure that the \"boat\" list is matching..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8bf072c73dff5e7076ed38ea9af8a8fb",
     "grade": true,
     "grade_id": "task4",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Executing test case 1 *****\n",
      "\n",
      "Homography estimated using the implemented Normalized DLT:\n",
      " [[  0.87545097   0.23238266   3.4699619 ]\n",
      " [ -0.21413475   0.87925678 129.60815544]\n",
      " [  0.00001108   0.0000304    1.        ]]\n",
      "Homography estimated using OPENCV:\n",
      " [[  0.87562125   0.23248716   3.42174345]\n",
      " [ -0.21411874   0.87937677 129.60221821]\n",
      " [  0.00001124   0.00003059   1.        ]]\n",
      "\n",
      "GROUND TRUTH COMPARISON FOR IMG1 -> IMG2 TRANSFORMATION:\n",
      "\n",
      "Comparison of ground truth (red), transformed points from implemented Normalized DLT (blue) and opencv (green) is saved in boat/result_all.png\n",
      "\n",
      "Comparison of ground truth (red) and transformed points from implemented Normalized DLT (blue) is saved in boat/result_observed.png\n",
      "\n",
      "Comparison of ground truth (red) and transformed points from implemented Normalized DLT (blue) is saved in boat/result_cv.png\n",
      "\n",
      "***** Test case 1 passed *****\n",
      "\n",
      "\n",
      "***** Executing test case 2 *****\n",
      "\n",
      "Homography estimated using the implemented Normalized DLT:\n",
      " [[  0.87545097   0.23238266   3.4699619 ]\n",
      " [ -0.21413475   0.87925678 129.60815544]\n",
      " [  0.00001108   0.0000304    1.        ]]\n",
      "Homography estimated using OPENCV:\n",
      " [[  0.87562125   0.23248716   3.42174345]\n",
      " [ -0.21411874   0.87937677 129.60221821]\n",
      " [  0.00001124   0.00003059   1.        ]]\n",
      "Error in percentage (for each cases):\n",
      " [[-0.00019446 -0.00044951  0.01409178]\n",
      " [ 0.0000748  -0.00013645  0.00004581]\n",
      " [-0.01365197 -0.00605626  0.        ]]\n",
      "\n",
      "***** Test case 2 passed *****\n",
      "\n",
      "***** Executing test case 3 *****\n",
      "\n",
      "Actual H value for test case:\n",
      " [[ 0.97  -0.018 16.03 ]\n",
      " [-0.006  0.963 12.741]\n",
      " [ 0.     0.     1.   ]]\n",
      "Observed H value for test case:\n",
      " [[ 0.97  -0.018 16.03 ]\n",
      " [-0.006  0.963 12.741]\n",
      " [-0.    -0.     1.   ]]\n",
      "\n",
      "***** Test case 3 passed *****\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import typing\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import image\n",
    "import cv2\n",
    "\n",
    "class Perform_DLT():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        np.set_printoptions(suppress=True)\n",
    "        \n",
    "    def get_correspondence_point(self, points_file: str, img_x: np.ndarray, img_xprime: np.ndarray) -> np.ndarray:\n",
    "        '''\n",
    "        Parser to read the correspondence points in img1 and img2\n",
    "        '''\n",
    "        \n",
    "        self.points_file = points_file\n",
    "        self.img_x = img_x\n",
    "        self.img_xprime = img_xprime\n",
    "\n",
    "        f = open(self.points_file)\n",
    "\n",
    "        image_points = dict()\n",
    "        for n,line in enumerate(f.readlines()):\n",
    "\n",
    "            line = line.replace('[','').replace(']','').strip()\n",
    "            pointlist = line.split('=')[1].split(';')\n",
    "            x = list()\n",
    "            y = list()\n",
    "\n",
    "            for point in pointlist:\n",
    "                x.append(int(point.split(',')[0]))\n",
    "                y.append(int(point.split(',')[1]))\n",
    "            image_points[n] = np.vstack((x,y))\n",
    "\n",
    "        return image_points[0], image_points[1]\n",
    "\n",
    "    def normalize(self, x: np.ndarray) -> np.ndarray:\n",
    "        \n",
    "        '''\n",
    "        Normalizes a given matrix, x by performing similarity transformation.\n",
    "        Now the centroid of the new points has (0,0)^T and the average distance \n",
    "        from the origin is square.root(2)\n",
    "        '''\n",
    "\n",
    "        x_bar = np.asarray(x)\n",
    "        m = np.mean(x,1)\n",
    "\n",
    "        deno = list()\n",
    "\n",
    "        for i in x.transpose():\n",
    "            deno.append(list(i-m))\n",
    "        deno = np.square(np.array(deno))\n",
    "        total = 0\n",
    "        for i in deno:\n",
    "            total = sum(i)**(1/2.) + total\n",
    "\n",
    "        s = 2**(1/2)/(total/len(deno))\n",
    "\n",
    "        T = np.array([[s, 0, -s*m[0]], [0, s, -s*m[1]], [0, 0, 1]])\n",
    "\n",
    "        x = np.vstack((x, np.ones((1,x.shape[1]))))\n",
    "\n",
    "        x_bar = np.dot(T, x)\n",
    "        \n",
    "        return x_bar, T\n",
    "\n",
    "    def DLT(self, x: np.ndarray, x_bar: np.ndarray) -> np.ndarray:\n",
    "        '''\n",
    "        Performs DLT on the x and x' provided\n",
    "        '''\n",
    "\n",
    "        # Initializations for A matrix\n",
    "        a_12 = list()\n",
    "        a_13 = list()\n",
    "        a_21 = list()\n",
    "        a_23 = list()\n",
    "        result = list()\n",
    "        \n",
    "        # Forming A matrix as provided in Reference 1 and Hartley and zisserman multiple view geometry\n",
    "\n",
    "        for i,j in zip(x.transpose(), x_bar.transpose()):\n",
    "\n",
    "            a_12= np.array([list(-np.dot(j[2],i.transpose()))])\n",
    "            a_13= np.array([list(np.dot(j[1],i.transpose()))])\n",
    "            a_21= np.array([list(np.dot(j[2],i.transpose()))])\n",
    "            a_23= np.array([list(-np.dot(j[0],i.transpose()))])\n",
    "\n",
    "            r1 = np.hstack((np.hstack((np.zeros((1,3)),a_12)),a_13))\n",
    "            r2 = np.hstack((np.hstack((a_21,np.zeros((1,3)))),a_23))\n",
    "\n",
    "            a = np.vstack((r1,r2))   \n",
    "\n",
    "            for k in a:\n",
    "                result.append(list(k))\n",
    "\n",
    "        A = np.array(result)\n",
    "        \n",
    "        \n",
    "        # Ah = 0 ;Minimizing ||Ah|| such that ||h||=1\n",
    "        # Solution by SVD\n",
    "        \n",
    "        U,s,Vt = np.linalg.svd(A)\n",
    "        V=Vt.T\n",
    "        h=V[:,-1] # Last column of V corresponding eigen vector to the smallest eigen value\n",
    "        \n",
    "        h = np.reshape(h,(3,3))\n",
    "\n",
    "        return h\n",
    "    \n",
    "    def desired_H(self, T_bar, T_prime_bar, H_normalized):\n",
    "        \n",
    "        '''\n",
    "        Used for finding H in unnormalized original co-ordinates from normalized H' by performing,\n",
    "        H = inverse(T') H' T\n",
    "        '''\n",
    "        non_scaled_H = np.dot(np.linalg.inv(T_prime_bar),(np.dot(H_normalized, T_bar)))\n",
    "        # Scaling H such that H(3,3) is 1.\n",
    "        desired_H = non_scaled_H/non_scaled_H[2][2]\n",
    "        \n",
    "        return desired_H\n",
    "    \n",
    "\n",
    "def test_case1(img1_path: str, img2_path:str, points_file: str):\n",
    "    '''\n",
    "    TEST: Given 2 images and correspondence points,\n",
    "    compares H from implemented normalized DLT and\n",
    "    H from openCV findHomography function.\n",
    "    \n",
    "    Provides visual outputs illustrating the comparison.\n",
    "    '''   \n",
    "    \n",
    "    print('***** Executing test case 1 *****\\n')\n",
    "    img1 = cv2.imread('boat/img1+points.png')\n",
    "    img2 = cv2.imread('boat/img2+points.png')\n",
    "\n",
    "    img2_observed = deepcopy(img2)\n",
    "    img2_cv = deepcopy(img2)\n",
    "\n",
    "    homography1 = Perform_DLT()\n",
    "    x, x_prime = homography1.get_correspondence_point(points_file, img1, img2)\n",
    "\n",
    "    homography1 = Perform_DLT()\n",
    "    x, x_prime = homography1.get_correspondence_point(points_file, img1, img2)   \n",
    "    x_bar, T_bar = homography1.normalize(x)\n",
    "    x_prime_bar, T_prime_bar = homography1.normalize(x_prime)\n",
    "    H_normalized = homography1.DLT(x_bar, x_prime_bar)\n",
    "    H = homography1.desired_H(T_bar, T_prime_bar, H_normalized)\n",
    "    print(\"Homography estimated using the implemented Normalized DLT:\\n\", H)\n",
    "\n",
    "    H_cv, status = cv2.findHomography(x.transpose(), x_prime.transpose())\n",
    "    print(\"Homography estimated using OPENCV:\\n\", H_cv)\n",
    "\n",
    "    for i in zip(x[0], x[1]):\n",
    "        cv2.circle(img1,(i),1,(0,0,255), 5)\n",
    "\n",
    "    for i in zip(x_prime[0], x_prime[1]):\n",
    "        cv2.circle(img2,(i),1,(0,0,255), 5) # RED\n",
    "        cv2.circle(img2_observed, i, 1, (0,0,255),5) # RED\n",
    "        cv2.circle(img2_cv, i, 1, (0,0,255),5) # RED\n",
    "\n",
    "    x_p_observed = np.dot(H,np.vstack((x,np.ones((1,x.shape[1])))))\n",
    "    x_p_observed = x_p_observed.astype(int)\n",
    "\n",
    "    x_p_cv = np.dot(H_cv,np.vstack((x,np.ones((1,x.shape[1])))))\n",
    "    x_p_cv = x_p_cv.astype(int)\n",
    "\n",
    "    for i in zip(x_p_observed[0], x_p_observed[1]):\n",
    "        cv2.circle(img2, i, 1, (255,0,0), 5) # BLUE\n",
    "        cv2.circle(img2_observed, i, 1, (255,0,0),5) # BLUE\n",
    "\n",
    "    for i in zip(x_p_cv[0], x_p_cv[1]):\n",
    "        cv2.circle(img2, i, 1, (0,255,0), 5) # GREEN\n",
    "        cv2.circle(img2_cv, i, 1, (0,255,0),5) # GREEN\n",
    "        \n",
    "    print('\\nGROUND TRUTH COMPARISON FOR IMG1 -> IMG2 TRANSFORMATION:')\n",
    "    \n",
    "    label1 = 'Red- Ground truth, Blue and Green - Using H from implemented DLT and OpenCV on img1 points'\n",
    "    cv2.putText(img2,label1, (20,20), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 255), 2, cv2.LINE_AA )\n",
    "    cv2.imwrite('boat/result_all.png', img2)\n",
    "    print('\\nComparison of ground truth (red), transformed points from implemented Normalized DLT (blue) and opencv (green) is saved in boat/result_all.png')\n",
    "    \n",
    "    label2 = 'Red- Ground truth, Blue- Using H from implemented DLT on img1 points'\n",
    "    cv2.putText(img2_observed,label2, (20,20), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 255), 2, cv2.LINE_AA )\n",
    "    cv2.imwrite('boat/result_observed.png', img2_observed)\n",
    "    print('\\nComparison of ground truth (red) and transformed points from implemented Normalized DLT (blue) is saved in boat/result_observed.png')\n",
    "    \n",
    "    label3 = 'Red- Ground truth, Green- Using H from OpenCV on img1 points'\n",
    "    cv2.putText(img2_cv,label3, (20,20), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 255), 2, cv2.LINE_AA )\n",
    "    cv2.imwrite('boat/result_cv.png', img2_cv)\n",
    "    \n",
    "\n",
    "    print('\\nComparison of ground truth (red) and transformed points from implemented Normalized DLT (blue) is saved in boat/result_cv.png')  \n",
    "    \n",
    "    print('\\n***** Test case 1 passed *****\\n')\n",
    "    \n",
    "def test_case2(img1_path: str, img2_path:str, points_file: str):\n",
    "    \n",
    "    '''\n",
    "    TEST: Given 2 set of correspondence points in 2 images, \n",
    "    compares H from implemented normalized DLT and\n",
    "    H from openCV findHomography function.\n",
    "    \n",
    "    Provides error value with each term of H matrix.\n",
    "    \n",
    "    The test passes if the error in all terms is below a tolerance say 0.05.\n",
    "    '''\n",
    "    \n",
    "    print('\\n***** Executing test case 2 *****\\n')\n",
    "    homography1 = Perform_DLT()\n",
    "    img1 = cv2.imread('boat/img1+points.png')\n",
    "    img2 = cv2.imread('boat/img2+points.png')\n",
    "    x, x_prime = homography1.get_correspondence_point(points_file, img1, img2)   \n",
    "    x_bar, T_bar = homography1.normalize(x)\n",
    "    x_prime_bar, T_prime_bar = homography1.normalize(x_prime)\n",
    "    H_normalized = homography1.DLT(x_bar, x_prime_bar)\n",
    "    H = homography1.desired_H(T_bar, T_prime_bar, H_normalized)\n",
    "    print(\"Homography estimated using the implemented Normalized DLT:\\n\", H)\n",
    "\n",
    "    H_cv, status = cv2.findHomography(x.transpose(), x_prime.transpose())\n",
    "    print(\"Homography estimated using OPENCV:\\n\", H_cv)\n",
    "    \n",
    "    error = ((H-H_cv)/H_cv)\n",
    "    print('Error in percentage (for each cases):\\n',error)\n",
    "    \n",
    "    difference = H-H_cv\n",
    "    \n",
    "    assert np.all(difference < 0.05),'Test case 2 failed'\n",
    "    print('\\n***** Test case 2 passed *****\\n')\n",
    "\n",
    "    \n",
    "def test_case3():\n",
    "    \n",
    "    '''Test case for DLT only (without normalization)\n",
    "    This is a DLT simple example case taken from \n",
    "    http://read.pudn.com/downloads75/ebook/273942/estimation-4.pdf\n",
    "    \n",
    "    In this test case, we check whether our implementation results\n",
    "    matches with the analytical solution provided in the reference.\n",
    "    '''\n",
    "    print('***** Executing test case 3 *****\\n')\n",
    "    x = np.array([[500,500,600,700,700],[500,700,600,500,700],[1,1,1,1,1]])\n",
    "    x_prime = np.array([[501,500,600,700,700],[500,700,600,500,700],[1,1,1,1,1]])\n",
    "    H_actual_answer = np.array([[0.970, -0.018, 16.030],[-0.006,0.963, 12.741],[0.000, 0.000, 1.000]])\n",
    "\n",
    "    test_case = Perform_DLT()\n",
    "    non_scaled_H = test_case.DLT(x,x_prime)\n",
    "    H_test_case = non_scaled_H/non_scaled_H[2][2]\n",
    "    H_test_case = np.round(H_test_case, 3)\n",
    "    \n",
    "    print('Actual H value for test case:\\n',H_actual_answer)\n",
    "    print('Observed H value for test case:\\n', H_test_case)\n",
    "    \n",
    "    assert np.allclose(np.squeeze(H_actual_answer), np.squeeze(H_test_case)),'Test case 3 failed'\n",
    "    print('\\n***** Test case 3 passed *****\\n')\n",
    "\n",
    "img_path1 = 'boat/img1+points.png'\n",
    "img_path2 = 'boat/img2+points.png' \n",
    "points_file = 'boat/homography.txt'\n",
    "test_case1(img_path1, img_path2, points_file)\n",
    "test_case2(img_path1, img_path2, points_file)\n",
    "test_case3()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6ffee384f689e6f73b8b2149c272d43f",
     "grade": true,
     "grade_id": "task4_md",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "From Test case 1, it is clear that the two set of corresponding points of image 1 and image 2 matches, find the uploaded files in the name boat/result_all.png, boat/result_observed.png, boat/result_cv.png. However, the visual and empirical results portray there is a tolerable error in mapping the points by homography between opencv and the implemented method with the ground truth provided. Test case 2 also illustrate this effect in terms of relative error with each element of the matrix.\n",
    "\n",
    "Test case 3 from reference 2 provided a solution for DLT from a set of 5 correspondence points. This test case checks whether the implementation is able to agree with the solution provided in the reference (an additional test case to check the empirical correctness of the DLT implemented). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "1. Rong Zhang, 'Automatic Computation of a Homography byRANSAC Algorithm', Purdue University, Accessed on: 25.04.2020, URL: https://engineering.purdue.edu/kak/courses-i-teach/ECE661.08/solution/hw4_s1.pdf.\n",
    "\n",
    "2. Estimation notes, Accessed on: 25.04.2020, URL: http://read.pudn.com/downloads75/ebook/273942/estimation-4.pdf."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
